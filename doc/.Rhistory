model_labels <- paste("GBM with depth =", model_values)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep = ""), header = F)
experiment_dir <- "../data/pets/" # This will be modified for different data sets.
# This is where my data lives (outside of Spring2018)
img_train_dir  <- paste(experiment_dir, "train/", sep="")
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep = ""), header = F)
label_train <- as.numeric(unlist(label_train) == "dog")
load("../output/siftfeatures.RData")
source("../lib/train.R")
source("../lib/test.R")
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(siftfeatures, label_train, model_values[k], K)
}
save(err_cv, file = "../output/err_cv.RData")
}
View(err_cv)
if(run.cv){
load("../output/err_cv.RData")
#pdf("../fig/cv_results.pdf", width=7, height=5)
plot(model_values, err_cv[,1], xlab = "Interaction Depth", ylab = "CV Error",
main = "Cross Validation Error", type = "n", ylim = c(0, 0.35))
points(model_values, err_cv[,1], col = "blue", pch=16)
lines(model_values, err_cv[,1], col = "blue")
arrows(model_values, err_cv[,1] - err_cv[,2], model_values, err_cv[,1] + err_cv[,2],
length = 0.1, angle = 90, code = 3)
#dev.off()
}
n_files <- length(list.files(img_train_dir))
n_files
dat <- matrix(NA, nrow = n_files, ncol = 3)
imgs <- vector("list", n_files)
for(i in 1:n_files){
img <- readImage(paste0(img_train_dir,  "pet", i, ".jpg"))
imgs[[i]] <- img
dat[i, 1:length(dim(img))] <- dim(img)
}
# How many B/W images?  All c olor.
table(dat[, 3])
# How many rows in each image?
table(dat[, 1])
paste0(img_train_dir,  "pet", 3, ".jpg")
img0 <-  readImage(paste0(img_dir, "pet", 1, ".jpg"))
img0 <-  readImage(paste0(img_train_dir, "pet", 1, ".jpg"))
mat1 <- as.matrix(img0)
n_r  <- nrow(img0)
# How many rows in each image?
table(dat[, 2])
imgshhh <- vector("list", n_files)
class(imgshhh)
class(img)
imgshhh$1
imgs$1
class(imgs)
class(imgs[[3]])
library(reticulate)
# If you are using anaconda, point reticulate to the correct conda environment
#use_condaenv('/anaconda3/bin/python')
use_python('/anaconda3/bin/python')
# for some reason I need to import cv2 and tensorflow before EBImage
# or everything breaks.
cv2 <- reticulate::import('cv2')
library("EBImage")
hog_values <- hog$compute(np_array(img * 255, dtype='uint8'))
winSize <- tuple(64L,64L)
blockSize <- tuple(16L,16L)
blockStride <- tuple(8L,8L)
cellSize <- tuple(8L,8L)
nbins = 9L
hog = cv2$HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins)
hog_values <- hog$compute(np_array(img * 255, dtype='uint8'))
img_resized <- cv2$resize(img, dsize=tuple(64L, 64L))
hog_values <- hog$compute(np_array(img_resized * 255, dtype='uint8'))
paste0("../output/feature_", "zip", "_", "train", ".RData")
paste0("../output/feature_",  "_HOG", ".RData")
paste0("../output/feature_",  "HOG", ".RData")
for(i in 1:n_files){
# img <- readImage(paste0(img_dir,  "pet", i, ".jpg"))
# imgs[[i]] <- img
img_resized[[i]] <- cv2$resize(imgs[[i]], dsize=tuple(64L, 64L))
#We thus compute a feature vector of length 1764 (in this case) which corresponds
#to the HOG features of our image.
### store vectorized pixel values of images
hog_values <- matrix(NA, 1764,n_files )
hog_values[i,] <- hog$compute(np_array(img_resized[[i]] * 255, dtype='uint8'))
}
img_resized<- vector("list", n_files)
for(i in 1:n_files){
# img <- readImage(paste0(img_dir,  "pet", i, ".jpg"))
# imgs[[i]] <- img
img_resized[[i]] <- cv2$resize(imgs[[i]], dsize=tuple(64L, 64L))
#We thus compute a feature vector of length 1764 (in this case) which corresponds
#to the HOG features of our image.
### store vectorized pixel values of images
hog_values <- matrix(NA, 1764,n_files )
hog_values[i,] <- hog$compute(np_array(img_resized[[i]] * 255, dtype='uint8'))
}
hog_values <- matrix(NA, 1764,n_files )
for(i in 1:n_files){
# img <- readImage(paste0(img_dir,  "pet", i, ".jpg"))
# imgs[[i]] <- img
img_resized[[i]] <- cv2$resize(imgs[[i]], dsize=tuple(64L, 64L))
### store vectorized pixel values of images
# hog_values[i,] <- hog$compute(np_array(img_resized[[i]] * 255, dtype='uint8'))
}
for(i in 1:n_files){
# img <- readImage(paste0(img_dir,  "pet", i, ".jpg"))
# imgs[[i]] <- img
#img_resized[[i]] <- cv2$resize(imgs[[i]], dsize=tuple(64L, 64L))
### store vectorized pixel values of images
hog_values[i,] <- hog$compute(np_array(img_resized[[i]] * 255, dtype='uint8'))
}
hog$compute(np_array(img_resized[[3]] * 255, dtype='uint8'))
a<-hog$compute(np_array(img_resized[[3]] * 255, dtype='uint8'))
class(a)
a<-as.vector(a)
dim(a)
class(a)
a
class(a)
hog_values[,3]<-a
View(hog_values)
for(i in 1:n_files){
# img <- readImage(paste0(img_dir,  "pet", i, ".jpg"))
# imgs[[i]] <- img
#img_resized[[i]] <- cv2$resize(imgs[[i]], dsize=tuple(64L, 64L))
### store vectorized pixel values of images
hog_values[,i] <- as.vector(hog$compute(np_array(img_resized[[i]] * 255, dtype='uint8')))
}
if(export){
save(hog_values, file = paste0("../output/feature_",  "HOG", ".RData"))
}
save(hog_values, file = paste0("../output/feature_",  "HOG", ".RData"))
class(hog_values)
dim(hog_values)
hog_value<-t(hog_values)
dim(hog_value)
save(hog_value, file = paste0("../output/feature_",  "HOG", ".RData"))
summary(hog_values)
hog_value[1,]
hog_value[,4]
model_values <- seq(3, 11, 2)
model_labels <- paste("GBM with depth =", model_values)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep = ""), header = F)
label_train <- as.numeric(unlist(label_train) == "dog")
source("../lib/train.R")
source("../lib/test.R")
source("../lib/cross_validation.R")
#load("../output/feature_HOG.RData")
if(run.cv){
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(hog_value, label_train, model_values[k], K)
}
save(err_cv, file = "../output/err_cvHOG.RData")
}
load("/Users/mac/Documents/GitHub/Spring2018/Project_Starter_Codes/Project2-PredictiveModelling/output/feature_train.RData")
class(dat_train)
View(dat_train)
class(hog_value)
dim(hog_value)
dim(dat_train)
source("../lib/cross_validation.R")
#load("../output/feature_HOG.RData")
if(run.cv){
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(hog_value, label_train, model_values[k], K)
}
save(err_cv, file = "../output/err_cvHOG.RData")
}
if(run.cv){
#load("../output/err_cvHOG.RData")
#pdf("../fig/cv_results.pdf", width=7, height=5)
plot(model_values, err_cv[,1], xlab = "Interaction Depth", ylab = "CV Error",
main = "Cross Validation Error", type = "n", ylim = c(0, 0.35))
points(model_values, err_cv[,1], col = "blue", pch=16)
lines(model_values, err_cv[,1], col = "blue")
arrows(model_values, err_cv[,1] - err_cv[,2], model_values, err_cv[,1] + err_cv[,2],
length = 0.1, angle = 90, code = 3)
#dev.off()
}
View(err_cv)
model_best <- model_values[1]
if(run.cv){
model_best <- model_values[which.min(err_cv[, 1])]
}
par_best <- list(depth = model_best)
# same chose the min var
#model_best<-9
#par_best <- list(depth = model_best)
View(par_best)
if(run.cv){
#load("../output/err_cvHOG.RData")
#pdf("../fig/cv_results.pdf", width=7, height=5)
plot(model_values, err_cv[,1], xlab = "Interaction Depth", ylab = "CV Error",
main = "Cross Validation Error", type = "n", ylim = c(0, 0.35))
points(model_values, err_cv[,1], col = "blue", pch=16)
lines(model_values, err_cv[,1], col = "blue")
arrows(model_values, err_cv[,1] - err_cv[,2], model_values, err_cv[,1] + err_cv[,2],
length = 0.1, angle = 90, code = 3)
#dev.off()
}
tm_train <- NA
tm_train <- system.time(fit_train <- train(hog_value, label_train, par_best))
View(err_cv)
save(fit_train, file = "../output/HOGfit_train.RData")
tm_train
cat("Time for training model=", tm_train[1], "s \n")
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
if(!require("pbapply")){
install.packages("pbapply")
}
library("EBImage")
library("gbm")
library("tidyverse")
paste0("../output/feature_", "zip", "_", "test", ".RData")
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
if(!require("pbapply")){
install.packages("pbapply")
}
library("EBImage")
library("gbm")
library("tidyverse")
setwd("~/Documents/GitHub/project-2-predictive-modelling-group-1/doc")
#right??
# Replace the above with your own path or manually set it in RStudio to where this rmd file is located.
experiment_dir <- "../data/pets/" # This will be modified for different data sets.
# This is where my data lives (outside of Spring2018)
img_train_dir  <- paste(experiment_dir, "train/", sep="")
run.cv            <- TRUE # run cross-validation on the training set
K                 <- 5    # number of CV folds
run.feature.train <- TRUE # process features for training set
run.test          <- TRUE # run evaluation on an independent test set
run.feature.test  <- TRUE # process features for test set
model_values <- seq(3, 11, 2)
model_labels <- paste("GBM with depth =", model_values)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep = ""), header = F)
label_train <- as.numeric(unlist(label_train) == "dog")
source("../lib/HOGfeature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, export = TRUE))
}
tm_feature_test <- NA
if(run.feature.test){
tm_feature_test <- system.time(dat_test <- feature(img_test_dir, export = TRUE))
}
tm_feature_train
cat("Time for constructing training features=", tm_feature_train[1], "s \n")
paste0("../output/feature_",  "HOG", ".RData")
load("/Users/mac/Documents/GitHub/project-2-predictive-modelling-group-1/output/feature_HOG.RData")
a<-hog_value[1:3]
a
a<-hog_value[1:3,]
a
dim(hog_value)
load("/Users/mac/Documents/GitHub/project-2-predictive-modelling-group-1/output/feature_HOG1.RData")
b<-hog_value[1:3,]
sum(a==b)
sum(a==b)/3
View(a)
View(b)
tm_feature_train
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
if(!require("pbapply")){
install.packages("pbapply")
}
library("EBImage")
library("gbm")
library("tidyverse")
setwd("~/Documents/GitHub/project-2-predictive-modelling-group-1/doc")
# Replace the above with your own path or manually set it in RStudio to where this rmd file is located.
experiment_dir <- "../data/pets/" # This will be modified for different data sets.
# This is where my data lives (outside of Spring2018)
img_train_dir  <- paste(experiment_dir, "train/", sep="")
run.cv            <- TRUE # run cross-validation on the training set
K                 <- 5    # number of CV folds
run.feature.train <- TRUE # process features for training set
run.test          <- TRUE # run evaluation on an independent test set
run.feature.test  <- TRUE # process features for test set
model_values <- seq(3, 11, 2)
model_labels <- paste("GBM with depth =", model_values)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep = ""), header = F)
label_train <- as.numeric(unlist(label_train) == "dog")
source("../lib/Neural_network_feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, export = TRUE))
}
tm_feature_train
cat("Time for constructing training features=", tm_feature_train[1], "s \n")
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
if(!require("pbapply")){
install.packages("pbapply")
}
library("EBImage")
library("gbm")
library("tidyverse")
setwd("~/Documents/GitHub/project-2-predictive-modelling-group-1/doc")
# Replace the above with your own path or manually set it in RStudio to where this rmd file is located.
experiment_dir <- "../data/pets/" # This will be modified for different data sets.
# This is where my data lives (outside of Spring2018)
img_train_dir  <- paste(experiment_dir, "train/", sep="")
run.cv            <- TRUE # run cross-validation on the training set
K                 <- 5    # number of CV folds
run.feature.train <- TRUE # process features for training set
run.test          <- TRUE # run evaluation on an independent test set
run.feature.test  <- TRUE # process features for test set
model_values <- seq(3, 11, 2)
model_labels <- paste("GBM with depth =", model_values)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep = ""), header = F)
label_train <- as.numeric(unlist(label_train) == "dog")
source("../lib/train.R")
source("../lib/test.R")
source("../lib/cross_validation.R")
load("../output/feature_NN.RData")
if(run.cv){
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(NN_values, label_train, model_values[k], K)
}
save(err_cv, file = "../output/err_cvNN.RData")
}
if(run.cv){
#load("../output/err_cvNN.RData")
#pdf("../fig/cv_results.pdf", width=7, height=5)
plot(model_values, err_cv[,1], xlab = "Interaction Depth", ylab = "CV Error",
main = "Cross Validation Error", type = "n", ylim = c(0, 0.35))
points(model_values, err_cv[,1], col = "blue", pch=16)
lines(model_values, err_cv[,1], col = "blue")
arrows(model_values, err_cv[,1] - err_cv[,2], model_values, err_cv[,1] + err_cv[,2],
length = 0.1, angle = 90, code = 3)
#dev.off()
}
View(err_cv)
model_best <- model_values[1]
if(run.cv){
model_best <- model_values[which.min(err_cv[, 1])]
}
par_best <- list(depth = model_best)
tm_train <- NA
tm_train <- system.time(fit_train <- train(NN_values, label_train, par_best))
save(fit_train, file = "../output/NNfit_train.RData")
tm_train
cat("Time for training model=", tm_train[1], "s \n")
View(err_cv)
getwd()
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("fastAdaboost")){
install.packages("fastAdaboost")
}
if(!require("pbapply")){
install.packages("pbapply")
}
library("EBImage")
library("fastAdaboost")
library("tidyverse")
setwd("~/Documents/GitHub/project-2-predictive-modelling-group-1/doc")
# Replace the above with your own path or manually set it in RStudio to where this rmd file is located.
experiment_dir <- "../data/pets/" # This will be modified for different data sets.
# This is where my data lives (outside of Spring2018)
img_train_dir  <- paste(experiment_dir, "train/", sep="")
run.cv            <- TRUE # run cross-validation on the training set
K                 <- 5    # number of CV folds
run.feature.train <- TRUE # process features for training set
run.test          <- TRUE # run evaluation on an independent test set
run.feature.test  <- TRUE # process features for test set
model_values <- seq(3, 11, 2)
model_labels <- paste("Adaboosting with tree depth =", model_values)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep = ""), header = F)
label_train <- as.numeric(unlist(label_train) == "dog")
set.seed(123)
s<-sample(1:2000, size=1500, replace=FALSE)
train.data  <- NN_values[s,]
train.label <- label_train[s]
test.data   <- NN_values[-s,]
test.label  <- label_train[-s]
#try ada
fit_ada<-adaboost(train.data, y = train.label,
tree_depth = 5,
n_rounds = 100, verbose = F)
?adaboost
??adaboost
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("JOUSBoost")){
install.packages("JOUSBoost")
devtools::install_github("molson2/JOUSBoost")
}
if(!require("pbapply")){
install.packages("pbapply")
}
library("EBImage")
library("JOUSBoost")
library("tidyverse")
#try ada
fit_ada<-adaboost(train.data, y = train.label,
tree_depth = 5,
n_rounds = 100, verbose = F)
label_trainada<-label_train
label_trainada<-label_train
label_trainada[which(label_trainada==0)] <-1
table(label_trainada)
label_trainada<-label_train
label_trainada[which(label_trainada==0)] <--1
table(label_trainada)
train.data  <- NN_values[s,]
train.labelada <- label_trainada[s]
test.data   <- NN_values[-s,]
test.labelada  <- label_trainada[-s]
#try ada
fit_ada<-adaboost(train.data, y = train.labelada,
tree_depth = 5,
n_rounds = 100, verbose = F)
print(fit_ada)
yhat_ada = predict(fit_ada, test.data)
summary(yhat_ada)
table(yhat_ada)
table(yhat_ada,test.labelada)
sum(yhat_ada==test.labelada)/500
source("../lib/Adatrain.R")
source("../lib/Adatest.R")
source("../lib/Adatrain.R")
source("../lib/Adatest.R")
source("../lib/cross_validation.R")
#load("../output/feature_NN.RData")
#Adaboosting label need to be -1 and 1, so made some transformation here
label_trainada<-label_train
label_trainada[which(label_trainada==0)] <--1
if(run.cv){
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(NN_values, label_trainada, model_values[k], K)
}
save(err_cv, file = "../output/err_cvNN_Ada.RData")
}
View(err_cv)
if(run.cv){
#load("../output/err_cvNN_Ada.RData")
#pdf("../fig/cv_results.pdf", width=7, height=5)
plot(model_values, err_cv[,1], xlab = "Interaction Depth", ylab = "CV Error",
main = "Cross Validation Error", type = "n", ylim = c(0, 0.35))
points(model_values, err_cv[,1], col = "blue", pch=16)
lines(model_values, err_cv[,1], col = "blue")
arrows(model_values, err_cv[,1] - err_cv[,2], model_values, err_cv[,1] + err_cv[,2],
length = 0.1, angle = 90, code = 3)
#dev.off()
}
#load("../output/err_cvNN_Ada.RData")
#pdf("../fig/cv_results.pdf", width=7, height=5)
plot(model_values, err_cv[,1], xlab = "Interaction Depth", ylab = "CV Error",
main = "Cross Validation Error", type = "n", ylim = c(0, 0.15))
if(run.cv){
#load("../output/err_cvNN_Ada.RData")
#pdf("../fig/cv_results.pdf", width=7, height=5)
plot(model_values, err_cv[,1], xlab = "Interaction Depth", ylab = "CV Error",
main = "Cross Validation Error", type = "n", ylim = c(0, 0.15))
points(model_values, err_cv[,1], col = "blue", pch=16)
lines(model_values, err_cv[,1], col = "blue")
arrows(model_values, err_cv[,1] - err_cv[,2], model_values, err_cv[,1] + err_cv[,2],
length = 0.1, angle = 90, code = 3)
#dev.off()
}
model_best <- model_values[1]
if(run.cv){
model_best <- model_values[which.min(err_cv[, 1])]
}
par_best <- list(depth = model_best)
tm_train <- NA
tm_train <- system.time(fit_train <- train(NN_values, label_train, par_best))
par_best
tm_train <- NA
tm_train <- system.time(fit_train <- train(NN_values, label_trainada, par_best))
save(fit_train, file = "../output/NN_Ada_fit_train.RData")
cat("Time for training model=", tm_train[1], "s \n")
