{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the images into a numpy array.\n",
    "#inspired by https://stackoverflow.com/questions/33369832/read-multiple-images-on-a-folder-in-opencv-python\n",
    "mypath = \"C:\\\\Users\\\\David\\\\Documents\\\\train\\\\\" #change this path to wherever your image data is\n",
    "# the below is a list of individual file names\n",
    "justfiles = [ f for f in listdir(mypath) if isfile(join(mypath,f)) ]\n",
    "#prepare my list of images\n",
    "images = np.empty(len(justfiles), dtype=object)\n",
    "#fill the list of images with the dog and cat images\n",
    "for n in range(0, len(justfiles)):\n",
    "  images[n] = cv2.imread( join(mypath,justfiles[n]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create an array of images to play around with\n",
    "tempimg = np.empty(500, dtype=object)\n",
    "for i in range(500):\n",
    "    tempimg[i] = images[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the labels, and prepare an array for a bool of labels, dog == True, cat == False\n",
    "labels = np.loadtxt(\"..\\\\data\\\\train_label.txt\", dtype = 'str')\n",
    "labelsb = np.empty(len(labels), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make labels a better string\n",
    "for i in range(len(labels)):\n",
    "    if ('d' in labels[i]):\n",
    "        labels[i] = 'dog'\n",
    "    else:\n",
    "        labels[i] = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fill labelsb\n",
    "for i in range(len(labels)):\n",
    "    if ('d' in labels[i]):\n",
    "        labelsb[i] = True\n",
    "    else:\n",
    "        labelsb[i] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make all images gray\n",
    "g_img = np.empty(len(images), dtype = object)\n",
    "for i in range(len(images)):\n",
    "    g_img[i] = cv2.cvtColor(images[i], cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#resize all images; make them uniform\n",
    "gu_img = np.empty(len(g_img), dtype = object)\n",
    "for i in range(len(images)):\n",
    "    gu_img[i] = cv2.resize(g_img[i], (128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gu_img[0:1400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train and test sets\n",
    "trn = gu_img[0:1400]\n",
    "tst = gu_img[1400:2000]\n",
    "# tmp train and test labels\n",
    "ltrn = labelsb[0:1400]\n",
    "ltst = labelsb[1400:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORB Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initiate STAR detector for all the images\n",
    "orbs = np.empty(len(gu_img), dtype = object)\n",
    "for i in range(len(gu_img)):\n",
    "    orbs[i] = cv2.ORB_create()\n",
    "\n",
    "# find the keypoints with ORB\n",
    "kps = np.empty(len(gu_img), dtype=object)\n",
    "for i in range(len(orbs)):\n",
    "    kps[i] = orbs[i].detect(gu_img[i],None)\n",
    "\n",
    "# compute the descriptors with ORB\n",
    "descrs = np.empty(len(kps), dtype=object)\n",
    "for i in range(len(kps)):\n",
    "    kps[i],descrs[i] = orbs[i].compute(gu_img[i],kps[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_size = 5\n",
    "bow = cv2.BOWKMeansTrainer(dict_size)\n",
    "\n",
    "for i in range(len(descrs)):\n",
    "    bow.add(np.float32(descrs[i]))\n",
    "\n",
    "dictionary = bow.cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 32)\n"
     ]
    }
   ],
   "source": [
    "orb2 = cv2.ORB_create()\n",
    "bowDiction = cv2.BOWImgDescriptorExtractor(orb2, cv2.BFMatcher(cv2.NORM_HAMMING))\n",
    "bowDiction.setVocabulary(dictionary)\n",
    "print(np.shape(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "C:\\projects\\opencv-python\\opencv\\modules\\features2d\\src\\matchers.cpp:744: error: (-215) _queryDescriptors.type() == trainDescType in function cv::BFMatcher::knnMatchImpl\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-785cbf6fe790>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbowfea\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgu_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgu_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mbowfea\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbowDiction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgu_img\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: C:\\projects\\opencv-python\\opencv\\modules\\features2d\\src\\matchers.cpp:744: error: (-215) _queryDescriptors.type() == trainDescType in function cv::BFMatcher::knnMatchImpl\n"
     ]
    }
   ],
   "source": [
    "bowfea = np.empty(len(gu_img), dtype=object)\n",
    "for i in range(len(gu_img)):\n",
    "    bowfea[i] = bowDiction.compute(gu_img[i], kps[i], descrs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'xfeatures2d'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-9d0c7b4cd12d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#surf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msurf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxfeatures2d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSURF_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msurf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextended\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mkps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_trn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'xfeatures2d'"
     ]
    }
   ],
   "source": [
    "#surf\n",
    "surf = cv2.xfeatures2d.SURF_create(400)\n",
    "surf.extended = True\n",
    "\n",
    "kps = np.empty(len(tmp_trn), dtype=object)\n",
    "for i in range(len(kps)):\n",
    "    kps[i],des[i] = surf.detectAndCompute(tmp_trn[i],None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words on orb features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section is from my project partner Yang He."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deeper Feature Extraction\n",
    "\n",
    "# Bag of word\n",
    "# clustering\n",
    "def bow_cluster(kmeans_obj, descriptor_stack):\n",
    "    kmeans_ret = kmeans_obj.fit_predict(descriptor_stack)\n",
    "    return kmeans_ret\n",
    "\n",
    "# generate vertical stack of descriptors\n",
    "def bow_vstack(desc_list):\n",
    "    stack = np.array(desc_list[0])\n",
    "    for rest in desc_list[1:]:\n",
    "        stack = np.vstack((stack, rest))\n",
    "    desc_stack = stack.copy()\n",
    "    return desc_stack\n",
    "\n",
    "# generate bag of words frequency matrix (shape: NUM_TRAIN_IMG * N_CLUSTER)\n",
    "def bow_get_freq_matrix(num_imgs, num_clusters, SIFT_list, kmeans_ret):\n",
    "    # initialization\n",
    "    matrix = np.array([np.zeros(num_clusters) for i in range(num_imgs)])\n",
    "    \n",
    "    # keep track of index of kmeans_ret\n",
    "    kmeans_id = 0\n",
    "    for i in range(num_imgs):\n",
    "        l = len(SIFT_list[i])\n",
    "        for j in range(l):\n",
    "            cluster_id = kmeans_ret[kmeans_id + j]\n",
    "            matrix[i][cluster_id] += 1\n",
    "        kmeans_id += l\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "descriptor_stack = bow_vstack(descrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans_obj = KMeans(n_clusters = 200)\n",
    "kmeans_ret = bow_cluster(kmeans_obj, descriptor_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_matrix = bow_get_freq_matrix(2000, 200, descrs, kmeans_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler().fit(vocab_matrix)\n",
    "vocab_matrix_std = scale.transform(vocab_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(vocab_matrix_std, labelsb, test_size = 0.2, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training using SVM @ 2018-03-03 18:10:32.355518\n",
      "Accuracy: 70.00%\n",
      "End training @ 2018-03-03 18:10:33.105365 Time Cost: 0:00:00.749847\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "print(\"Start training using SVM @ \" + str(start_time))\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "pred = np.asarray(clf.predict(X_test))\n",
    "accuracy = (pred == y_test).mean()\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))\n",
    "end_time = datetime.now()\n",
    "print(\"End training @ \" + str(end_time) + \" Time Cost: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train other classifiers with BOW ORB features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training using GBC @ 2018-03-03 19:37:03.526160\n",
      "End training @ 2018-03-03 19:37:04.539437 Time Cost: 0:00:01.013277\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "print(\"Start training using GBC @ \" + str(start_time))\n",
    "\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"End training @ \" + str(end_time) + \" Time Cost: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training using GBC @ 2018-03-03 19:37:08.910028\n",
      "Accuracy: 68.25%\n",
      "End training @ 2018-03-03 19:37:08.913029 Time Cost: 0:00:00.003001\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "print(\"Start training using GBC @ \" + str(start_time))\n",
    "\n",
    "pred = np.asarray(clf.predict(X_test))\n",
    "accuracy = (pred == y_test).mean()\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"End training @ \" + str(end_time) + \" Time Cost: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training using RF @ 2018-03-03 19:37:15.823833\n",
      "End training @ 2018-03-03 19:37:15.891893 Time Cost: 0:00:00.068060\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "print(\"Start training using RF @ \" + str(start_time))\n",
    "\n",
    "clf = ensemble.RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"End training @ \" + str(end_time) + \" Time Cost: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training using RF @ 2018-03-03 19:37:17.934256\n",
      "Accuracy: 59.00%\n",
      "End training @ 2018-03-03 19:37:17.938260 Time Cost: 0:00:00.004004\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "print(\"Start training using RF @ \" + str(start_time))\n",
    "\n",
    "pred = np.asarray(clf.predict(X_test))\n",
    "accuracy = (pred == y_test).mean()\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"End training @ \" + str(end_time) + \" Time Cost: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training using ADB @ 2018-03-03 19:38:29.615501\n",
      "End training @ 2018-03-03 19:38:30.010053 Time Cost: 0:00:00.394552\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "print(\"Start training using ADB @ \" + str(start_time))\n",
    "\n",
    "clf = ensemble.AdaBoostClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"End training @ \" + str(end_time) + \" Time Cost: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training using ADB @ 2018-03-03 19:38:33.285070\n",
      "Accuracy: 62.75%\n",
      "End training @ 2018-03-03 19:38:33.297087 Time Cost: 0:00:00.012017\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "print(\"Start training using ADB @ \" + str(start_time))\n",
    "\n",
    "pred = np.asarray(clf.predict(X_test))\n",
    "accuracy = (pred == y_test).mean()\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"End training @ \" + str(end_time) + \" Time Cost: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "winSize = (128,128)\n",
    "blockSize = (16,16)\n",
    "blockStride = (8,8)\n",
    "cellSize = (8,8)\n",
    "nbins = 9\n",
    "\n",
    "hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins)\n",
    "\n",
    "des = np.empty(len(trn), dtype=object)\n",
    "for i in range(len(des)):\n",
    "    des[i] = hog.compute(trn[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "des_tst = np.empty(len(tst), dtype=object)\n",
    "for i in range(len(des_tst)):\n",
    "    des_tst[i] = hog.compute(tst[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8100,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(des[0].flatten()).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#flatten the arrays\n",
    "f_trn = np.empty(len(trn),dtype=object)\n",
    "for i in range(len(trn)):\n",
    "    f_trn[i] = trn[i].flatten()\n",
    "\n",
    "f_tst = np.empty(len(tst),dtype=object)\n",
    "for i in range(len(tst)):\n",
    "    f_tst[i] = tst[i].flatten()\n",
    "  \n",
    "f_des = np.empty(len(des),dtype=object)\n",
    "for i in range(len(f_des)):\n",
    "    f_des[i] = des[i].flatten()\n",
    "\n",
    "f_des_tst = np.empty(len(tst), dtype=object)\n",
    "for i in range(len(f_des_tst)):\n",
    "    f_des_tst[i] = des_tst[i].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reformat the arrays\n",
    "f_trn = np.vstack(f_trn)\n",
    "f_tst = np.vstack(f_tst)\n",
    "f_des = np.vstack(f_des)\n",
    "f_des_tst = np.vstack(f_des_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 8100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_des.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Models With HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the logistic reggresion modelmodel\n",
    "lrmodel = linear_model.LogisticRegression(solver='sag')\n",
    "lrmodel.fit(f_des,ltrn)#lrmodel.fit(ftmp_trn,tmp_ltrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59333333333333327"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (sum(lrmodel.predict(f_des_tst) ^ ltst)/600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete @ 2018-03-03 13:26:43.006803 Time Cost: 0:01:55.547045\n"
     ]
    }
   ],
   "source": [
    "#fit a gradient boosting algorithm\n",
    "start_time = datetime.now()\n",
    "\n",
    "gbcmodel = ensemble.GradientBoostingClassifier()\n",
    "gbcmodel.fit(f_des,ltrn)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"complete @ \" + str(end_time) + \" Time Cost: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete @ 2018-03-03 13:27:05.899684 Time Cost: 0:00:00.016026\n",
      "0.63\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "acc = 1 - (sum(gbcmodel.predict(f_des_tst) ^ ltst)/600)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"complete @ \" + str(end_time) + \" Time Cost: \" + str(end_time - start_time))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete @ 2018-03-03 13:33:37.055442 Time Cost: 0:01:04.129575\n"
     ]
    }
   ],
   "source": [
    "#fit adaboost\n",
    "start_time = datetime.now()\n",
    "\n",
    "adbmodel = ensemble.AdaBoostClassifier()\n",
    "adbmodel.fit(f_des,ltrn)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"complete @ \" + str(end_time) + \" Time Cost: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete @ 2018-03-03 13:33:52.011831 Time Cost: 0:00:00.181946\n",
      "0.625\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "acc = 1 - (sum(adbmodel.predict(f_des_tst) ^ ltst)/600)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"complete @ \" + str(end_time) + \" Time Cost: \" + str(end_time - start_time))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete @ 2018-03-03 13:27:16.673594 Time Cost: 0:00:01.025556\n"
     ]
    }
   ],
   "source": [
    "#fit random forest\n",
    "start_time = datetime.now()\n",
    "\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "rf.fit(f_des,ltrn)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"complete @ \" + str(end_time) + \" Time Cost: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete @ 2018-03-03 13:27:19.493271 Time Cost: 0:00:00.009994\n",
      "0.601666666667\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "acc = 1 - (sum(rf.predict(f_des_tst) ^ ltst)/600)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"complete @ \" + str(end_time) + \" Time Cost: \" + str(end_time - start_time))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete @ 2018-03-03 13:27:41.761828 Time Cost: 0:00:15.627986\n"
     ]
    }
   ],
   "source": [
    "#fit svm\n",
    "start_time = datetime.now()\n",
    "\n",
    "svmmodel = svm.SVC(kernel='rbf')\n",
    "svmmodel.fit(f_des,ltrn)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"complete @ \" + str(end_time) + \" Time Cost: \" + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete @ 2018-03-03 13:28:02.375045 Time Cost: 0:00:05.556145\n",
      "0.676666666667\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "acc = 1 - (sum(svmmodel.predict(f_des_tst) ^ ltst)/600)\n",
    "end_time = datetime.now()\n",
    "print(\"complete @ \" + str(end_time) + \" Time Cost: \" + str(end_time - start_time))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
